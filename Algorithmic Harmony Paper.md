# Algorithmic Harmony Paper

## Abstract

> *This paper documents the Modular Music Theory System, a web-based compositional tool that combines algorithmic generation, interactive harmonic analysis, and real-time notation to assist composers in exploring non-functional harmony, container chords, modal reharmonization, and more. Inspired by Athanasius Kircher's 17th-century music theory treatise Arca Musarithmica and jazz pianist Barry Harris's pedagogical methods for exploring harmony, the system translates numeric sequences, lexical inputs, and phonetic patterns into musical material through a modular JavaScript architecture generated by GitHub Copilot, Kiro, Manus, Claude, and ChatGPT via custom prompt engineering. A semantic word-mapping engine connects descriptive language to harmony/melody/scale/intervals/context/history/emotional attributes - for example, translating inputs like "medieval city ancient explore" into modal suggestions (C Dorian) that approximate the harmonic language we’re trying to convey which in this case is imitating the harmonic style of Jeremy Soule’s piece Secunda from The Elder Scrolls V: Skyrim soundtrack (2011) in relation to when the song plays during your travels around the game world’s ancient provinces. The tool features a random number generator for creating melodies and chord progressions, a circle of fifths/fourths/chromatic wheel that visualizes scales, an ever-growing scale library (100+ scales), a container chord finder expanding upon Harris's related concepts, a sheet music generator, MIDI export ability, a visualizer that shows scales and chords as a solar system, and much more. This paper attempts to explain the system's design philosophy, documents its core modules, and presents compositional case studies demonstrating how algorithmic constraints can illuminate unexpected harmonic possibilities. The central thesis is simple: by understanding music's underlying mathematical structure, we can intentionally shape emotional impact while expanding our compositional vocabulary beyond habitual patterns.*

## Paper

Algorithmic Harmony: Composing with the Modular Music Theory System

From Kircher's Arca Musarithmica to Modern JavaScript

Author: Parker Chace







Introduction: All Music is Algorithmic

Composers have always worked with systems. A major seventh chord is 4 + 3 + 4 semitones; a minor seventh chord is 3 + 4 + 3 semitones; a diminished chord is 3 + 3 semitones. These are algorithmic relationships - patterns we can manipulate, transform, and recombine. The question is not whether to use algorithms in composition, but whether we do so consciously and intentionally.

Just as birds evolved countless vocalizations for different purposes - mate attraction, territorial defense, alarm calls, and individual expression - musicians express themselves across diverse contexts: artistic individualism, service to others, lament, celebration. Algorithmic composition tools expand harmonic possibilities while keeping alive the traditions of those who came before us.



Historical Precedent: The First "Music Computer" (1650)

The earliest algorithmic composition system I could find was Athanasius Kircher's Arca Musarithmica (1650), a combinatorial device using wooden rods that enabled the amusikos (non-musician) to compose polyphony. Kircher's philosophy centered on Numerus Sonorus - the concept of "sounding number" - which treated musical structure as manipulable through mathematical operations [11]. The Modular Music Theory System

continues this lineage, translating numbers and words into musical material through transparent, user-controlled algorithms.



Barry Harris and Container Chords

The development of this system was directly inspired by pedagogical practices that treat randomly chosen numbers as compositional seeds. One of Barry Harris's masterclasses demonstrated how you can write numbers on scraps of paper that can map to scales and chords and pick them up in a random order, transforming arbitrary sequences into musical starting points that represent scale degrees; either what the melody is, what scale degree will be the root of the chord, or what scale degree is contained within other chords diatonic or nondiatonic - even a combination of them all (https://www.youtube.com/watch?v=0-IRJsAi0ek) [10]. At American University’s Songwriter Hub, Professor Alex Salser guest spoke a demonstrated a similar method using numbers on randomly picked up scraps of paper to decide what scale degree will be the root of the chord - for example, in the key of C major, picking up a 1, then a 4, then a 5, means you play the diatonic chords Cmajor7, Fmajor7, then G7.

Harris's key contributions that informed this tool's design include:



1.	Container Chords: Chords selected not for their functional role but for their ability to "contain" specific melody notes, enabling smooth voice-leading and unexpected harmonic color. Instead of asking "what chord should come next functionally?" Harris asks "what chord contains the notes I need?"

2.	The Sixth Diminished Scale: Harris's method of inserting passing diminished chords between diatonic harmonies, creating chromatic voice-leading while maintaining tonal coherence.

3.	Chromatic Approaches: Systematic use of half-step motion to connect diatonic structures, often through upper or lower neighbor motion.



The Container Chord Finder module directly implements Harris's first concept especially, allowing composers to click desired melody notes and receive all possible chords that contain those pitches - prioritizing voice-leading and color over functional progression.



Semantic Mapping: From Words to Modal Color

One compositional goal driving the semantic mapping features was to enable intuitive emotional-to-harmonic translation. For example, inputting words like "medieval city ancient explore" should approximate the harmonic language Jeremy Soule achieved in "Secunda" from the Skyrim soundtrack - C Dorian with prominent i - IV motion, repeating melodic patterns with wide intervallic leaps, and modal stability that evokes antiquity.

This kind of lexical-to-modal mapping requires the system to associate "ancient" with church modes, "explore" with open intervallic structures, and "medieval" with Dorian or Phrygian qualities. The generative-word-mapper.js engine implements this through a pattern library that connects semantic attributes to scale characteristics and emotional frameworks like BRECVEM [1, 9].

Methods: System Architecture

[INSERT FIGURE: Main Interface Overview HERE]

The system is implemented as a modular set of JavaScript engines included in interface provides multiple views for exploration and composition.



Core Analysis Engines

phonetic-analyzer.js: Derives phonetic features (syllable counts, stress patterns, vowel quality) that can influence melodic contour choices. For example, words with stressed first syllables might map to melodies with strong downbeats, while dactylic patterns (stressed-unstressed-unstressed) might suggest triplet figures.



generative-word-mapper.js: Fuses phonetic signals with semantic inferences to build an attribute profile for an input word or phrase. Semantic inference tries a networked API when available with a robust fallback to an internal pattern library of lexical cues mapped to attributes (e.g., "joy" → bright, high-range; "ancient" → modal, Dorian/Phrygian; "storm" → dissonant, unstable). This mapper also accepts numeric sequences, interpreting digits as scale degrees, pitch classes, or rhythmic tokens depending on user settings.



music-theory-engine.js: Contains the curated scale library (60+ named scales across Western and non-Western traditions including church modes, jazz scales, pentatonics, hexatonics, and approximations of maqamat and ragas). The object flags entries as approximations when 12-TET encoding cannot accurately represent microtonal traditions. Scales are stored as pitch-class sets with metadata including characteristic intervals, emotional associations, and cultural context.



scale-intelligence-engine.js: Computes weighted scores for scales based on input attributes. The scoring mixes four components - emotional valence/arousal (40%), semantic labels (30%), prominent intervals (20%), and contextual tags (10%) in the default "Balanced" preset. Users can select alternate presets ("Functional," "Emotional," "Color/Synesthesia") or manually adjust weights. The engine includes controlled randomness to balance predictability with discovery.



Interactive Interface Modules



1. Number Generator: Bias-free motif seed generation with optional preferred-note constraints. Users can generate random sequences and apply transformations (reverse, invert, rotate, randomize) to explore variations. The generator treats sequences as scale-degree melodies, harmonic roots, or rhythmic patterns depending on the selected interpretation mode.

2. Scale Library with Global Selector: Comprehensive collection with quick-audition dropdown. Each scale includes its interval formula, characteristic sound, and typical usage context (e.g., "Phrygian: dark, Spanish/Middle Eastern flavor, flat-2 is distinctive").

3. Piano Visualizer: Live highlighting of scale degrees and chord tones with dynamic key-range fitting. The visualizer adjusts to show only the relevant octave span, reducing visual clutter.

4. Scale Circle Explorer: Interactive circular visualization inspired by circle-of-fifths diagrams. Users can click scale degrees to hear them and visualize intervallic relationships spatially.

5. Unified Chord Explorer: Radial substitution interface organized by harmonic families. Chords are grouped by relationship type: parallel modes (Cmaj7↔Cm7), secondary dominants (V/ii, V/iii), tritone substitutions (V7↔bII7), and modal interchange options (borrowed from parallel minor/major). This layout makes non-functional reharmonization intuitive. Users see substitute options at a glance rather than scrolling through linear lists. This tool is great for people wanting to spice up their (re)harmonization or explore logical chord groupings.

6. Container Chord Finder: The core implementation of Barry Harris's container chord concept. Users click desired melody notes on a piano interface, and the system returns all chords (triads, sevenths, ninths, elevenths, thirteenths) that contain those pitches. Results are sorted by voice-leading efficiency and harmonic color. This bypasses functional thinking entirely - if your melody outlines D and B, why use G major just because it's V? The finder suggests Dm6, Bm7b5, Gmaj7, G6, Bø7, and others, letting you choose based on color and context rather than Roman numeral progression. The numbers I generated were 272721 and in the first example, those numbers strictly represent melody notes, whereas the second example has 272721 represented by notes contained in diatonic chords (not necessarily the melody):

7.	Sheet Music Generator: SVG-based notation with grand staff option, proper key signatures and accidentals, and per-measure rendering. The generator stores complete voice data per chord, allowing users to edit voicings and see results immediately in notation. Here is an example of 272721 with generated voice leading that uses multiple voicings and inversions:

8.	Progression Builder: Fine-tune harmonic complexity via sliders controlling chord quality (triads vs. extensions), density (3-note vs. 6-note voicings), and chromaticism. The builder includes a reharmonization mode where users can click any chord in a progression to substitute it, add passing chords before/after, or modify voicing. This user interface/experience is in a work-in-progress state.



MIDI Integration and Playback



The system includes a MIDI export process, play and stop buttons, BPM to see how your harmony is affected by tempo, a sheet music debug log copier, and a work in progress tool for exporting sheet music/midi straight to a DAW of your choice. I will eventually compile it using other tools/skills I have yet to personally develop.



Scoring and Decision Rules

Candidate scales are scored by comparing generated attribute vectors (emotional valence/arousal via BRECVEM mechanisms approximated to coded sliders via AI machine learning, semantic labels from word mapping, prominent intervals, contextual tags) to stored scale profiles. The BRECVEM framework [9] maps measurable features to emotion mechanisms: sudden dynamic spikes → brain-stem reflexes, tempo/pulse → rhythmic entrainment, mode/intervals → emotional contagion, harmonic surprise → expectancy. The engine aggregates mechanism signals into a single emotional score, making recommendations explainable: "Phrygian suggested because 'dark' attribute matches low valence

+ flat-2 interval signals minor-key instability."



For science and transparency, users can version and save weight calibrations for reproducibility. The settings are visible in, allowing researchers to document specific configurations.



Case Studies: Compositional Applications



are chord tones. To avoid "cookie-cutter" progressions, I used the Container Chord Finder.

[INSERT FIGURE: Container Chord Finder showing Dm6 selection HERE]



Clicking D and B returned multiple options; I selected Dm6 because:



 	D and B are a sixth apart—the chord name reflects the intervallic relationship

 	Dm is diatonic (ii chord) but the added sixth creates unexpected color

 	B (scale degree 7, the leading tone) creates tension without dominant function

 	The voicing sounds richer and less predictable than G major



The melody continues over measures 2-4 with similar logic. For the final C, I "drop-2" a Cmaj7 voicing (second-highest voice down an octave), which sounds momentarily unresolved, then step the bass from B down to A (vi chord) for a deceptive cadence rather than predictable tonic resolution.



Second Harmonization: Numbers as Harmonic Containers

In the second approach, 272721 represents scale degrees that must appear within chord voicings rather than as melody on top. The constraint is that each harmony must contain the specified degree somewhere in its voicing. I kept chords diatonic or functionally chromatic (V/V) but let the numbers dictate voice distribution rather than melodic contour.

This demonstrates the system's interpretive flexibility: the same sequence generates melody-driven harmony or harmonic containers depending on compositional intent.



Case Study 2: Reharmonizing a Generated Motif

[INSERT FIGURE: Chord Explorer showing Em7→Emaj7 substitution HERE]



Using the Number Generator, I created the sequence 7-2-4-3 in C major with "Numbers as Roots" mode enabled, meaning each digit maps to its diatonic chord (7=Bm7b5, 2=Dm7, 4=Fmaj7, 3=Em7).

The initial progression was Bm7b5 – Dm7 – Fmaj7 – Em7. Functional but predictable. In the Chord Explorer, I clicked Em7 and selected its parallel major variant, Emaj7, borrowing from C Lydian. This creates a brighter, unexpected shift—the E major triad is non-diatonic but resolves smoothly because the voice-leading is efficient (only one note moves by half-step).

The tool made this substitution intuitive by grouping parallel modes together visually. Without the radial interface, I might not have considered this option.



Case Study 3: Adding Passing Chords to an Existing Progression

[INSERT FIGURE: Passing Chords Workflow - Romance Song Example HERE]



I entered a pre-existing progression into the system: Dmaj7 – Gmaj7 – F#m7 – B7 – Em7 – F#m7 – Gm7 – Am7 – Em7b5 – Dmaj7

This is a romance song with an ascending sequence (Em7-F#m7-Gm7-Am7-Em7b5) that needs to return to Dmaj7 in a "sweet, velvety" way. Following Barry Harris's approach of exploring scales a fifth above the target chord, I searched for scales in A (a fifth above D) that contain a D major chord.

I typed 1 2 3 4 5 6 7 into the Number Generator to visualize all diatonic chords in candidate A scales. The Scale Library suggested A Dorian b2 (also called Phrygian ♮6), which includes a D7 chord on scale degree IV.

[INSERT FIGURE: A Dorian b2 Scale Diagram with Chords HERE]



The scale's chords are: Am7 – Baug(maj7) – C7 – D7 – Eø7 – F#ø7 – Gmaj7. I selected the Baug(maj7) → C7

→ D7 sequence as passing chords between Em7b5 and Dmaj7. The augmented chord adds exotic color, C7 creates chromatic motion (C♮ to B in the resolution to Dmaj7), and D7 provides dominant function.

This workflow—target chord → fifth above → exotic scale exploration → chromatic passing motion—would have been tedious without the tool's integrated scale library and notation generator. The system enabled rapid experimentation that I wouldn't have pursued manually.





Results and Reflection



What Worked Well

Container Chord Finder: This was the most valuable module for composition. Being able to click melody notes and instantly see all harmonic options transformed my approach to voice-leading. In the 272721 example, discovering Dm6 as an alternative to G major opened up an entire palette of sixth chords I hadn't been using regularly.



Number Generator with Transformations: The random sequences forced me out of habitual patterns. I would never have naturally chosen D-B-D-B-D-C as a motif, but the constraint led to discoveries I wouldn't have made otherwise. The rotate and invert functions helped me generate variations while maintaining motivic coherence.

MIDI Export to DAW: The FastAPI/loopMIDI integration eliminated transcription friction. I could audition progressions with realistic piano and string sounds immediately, making aesthetic judgments more confidently than with JavaScript synth playback alone.

Visual Feedback: The Piano Visualizer and Scale Circle Explorer provided immediate reinforcement of theoretical concepts. Seeing scale degrees light up as I clicked through container chords helped me internalize intervallic relationships.

Radial Chord Explorer: Once I understood the layout, the grouped substitution options (parallel modes, secondary dominants, modal interchange) made reharmonization significantly faster than scrolling through dropdown menus.



What Was Less Effective

Semantic Mapping Granularity: The word-to-scale engine worked well for broad emotional terms ("dark," "bright," "ancient") but struggled with abstract concepts or neologisms. When I input "ephemeral crystalline," the system defaulted to generic bright/high-range suggestions rather than capturing the specific textural quality I intended. The fallback heuristics are coarse—improving this would require integrating word embedding models or training on compositional corpora.

Chord Substitution UI Complexity: The Chord Explorer's radial layout is powerful but has a steep learning curve. First-time users expect linear progression displays; the circular organization is disorienting initially.

Several test users (classmates I demoed for) struggled to find the substitution button and didn't intuitively understand the harmonic family groupings.

Numeric Interpretation Ambiguity: The system requires explicit configuration of how to interpret number sequences (scale degrees vs. pitch classes vs. rhythmic values). While this flexibility is useful once understood, it confused early users who expected a single "correct" interpretation. Better defaults or a wizard-style setup flow might help.

12-TET Limitations for Semantic Goals: When exploring "medieval" or "ancient" attributes, the system suggests Dorian and Phrygian modes, which is theoretically sound. However, authentic medieval polyphony uses Pythagorean tuning, and many "ancient" musical traditions (Arabic maqamat, Indian ragas) require microtones. The 12-TET approximations often miss the subtle inflections that create the intended emotional effect. For the Secunda/Skyrim goal, this was acceptable because Soule also composed in 12-TET, but for ethnomusicologically informed composition, the limitation is significant.



Compositional Insights

Working with algorithmic constraints illuminated harmonic relationships I'd previously ignored. The container chord approach—prioritizing voice-leading over function—led me to use minor sixth chords, half-diminished



sevenths, and augmented major sevenths far more frequently than in my previous work. These sonorities had seemed exotic or jazz-specific before; now I recognize them as color options available in any harmonic context.

The tool doesn't compose music—it illuminates possibilities. Every generated sequence required interpretation, every scale suggestion required contextual judgment, every container chord required voicing decisions. The human element remained central: choosing which random numbers to use, deciding how to interpret them, selecting among suggested scales, and ultimately voicing and orchestrating the material.

The most valuable compositional shift was psychological: the tool gave me permission to use non-functional harmony without feeling I was "breaking rules." By making Harris's container chord method interactive and visual, the system reframed harmony as a color palette rather than a ruleset. This mindset change persisted even when composing away from the tool.





Discussion



Broader Context: Algorithmic Composition Lineage

This project situates itself within a tradition stretching from Kircher's mechanical Arca through Schillinger's mathematical composition system, Cage's chance operations, Xenakis's stochastic music, and contemporary machine learning approaches. Unlike black-box AI systems (e.g., OpenAI's MuseNet, Google's Magenta), the Modular Music Theory System maintains transparency: users see why each scale or chord was suggested and can adjust weighting parameters to align with aesthetic preferences.

The tool also serves a pedagogical function. By making Harris's container chord concepts interactive, it helps students understand voice-leading and substitution principles that seem abstract in lecture format. The Scale Circle Explorer and Piano Visualizer provide immediate visual feedback that reinforces theoretical learning.



Limitations and Constraints

Approximation of Non-Western Tunings: All scales are encoded in 12-TET. Arabic maqamat like Rast and Bayati, Indian ragas like Bhairavi, and Turkish makam cannot be accurately represented. The system flags these

as approximations in	, but users seeking authentic microtonal composition must look elsewhere.

Future versions could integrate Scala format tuning files and JavaScript microtonal playback libraries.



Semantic Inference Dependency on Fallback Heuristics: When external APIs are unavailable, the pattern library produces coarse mappings for edge-case inputs. Technical jargon, culturally specific terms, and compound neologisms often default to generic suggestions. Integration with WordNet or sentiment analysis APIs would improve granularity.

UI Discoverability: Advanced features (chord substitution workflows, reharmonization modes, weight adjustment) have steep learning curves. The interface assumes users understand jazz harmony and modal theory. A tutorial mode or progressive disclosure UI would make the tool more accessible to beginners.



No Rhythmic or Formal Generation: The system focuses exclusively on pitch and harmony. Generated numbers can be interpreted rhythmically, but the tool doesn't provide notation or analysis for rhythmic patterns, formal proportions, or phrase structure. Extending the number-to-music mapping to include these dimensions would create a more complete compositional assistant.





Future Work

1.	Microtonal Tuning Support: Integrate Scala tuning file import and extend the playback engine to support arbitrary tunings. This would enable authentic representation of maqamat, ragas, and experimental scales.

2.	Enhanced Semantic Mapping: Incorporate word embedding models (Word2Vec, GloVe) or fine-tune language models on compositional descriptions to improve lexical-to-musical mappings. Training data could come from album liner notes, concert program notes, or music reviews that connect descriptive language to specific pieces.

3.	User Testing and Iteration: Conduct formal usability studies with composers and students to identify interface pain points. The current design reflects my workflow; broader testing would reveal where the interface fails other users' mental models.

4.	Advanced Export Options: Add dynamics, articulations, tempo markings, and rehearsal letters to MIDI/notation export for professional use.

5.	Citation Curation: Consult ethnomusicology faculty and the AU music librarian to improve scale sourcing. Several entries are from secondary references or online databases; tracking down original ethnographic documentation would increase scholarly credibility.

6.	Machine Learning Integration: Experiment with transformer models trained on chord progression corpora to suggest context-aware substitutions. This would complement (not replace) the rule-based system, balancing novelty with stylistic coherence.

7.	Rhythmic and Formal Dimensions: Extend mappings to include rhythmic patterns (numbers → subdivision schemes) and formal structures (numbers → phrase lengths, sectional proportions).

8.	Collaborative Features: Enable users to save and share weight calibrations, scale selections, and progressions, fostering a community of practice.





Conclusion

The Modular Music Theory System demonstrates how algorithmic tools can expand compositional vocabulary while maintaining human creativity at the center of the process. Rooted in Kircher's Arca Musarithmica and informed by Barry Harris's pedagogical methods, the system provides transparent, theory-based suggestions that illuminate possibilities rather than dictate outcomes.



The compositional case studies—272721 harmonization, modal reharmonization, and passing chord insertion—show how algorithmic constraints can lead to discoveries outside habitual patterns. The Container Chord Finder, implementing Harris's voice-leading approach, proved particularly valuable for exploring non-functional harmony.

Central thesis confirmed: by understanding music's underlying mathematical structure—interval ratios, scale patterns, voice-leading efficiency—we can intentionally shape emotional impact while keeping exploratory traditions alive. The tool doesn't replace compositional judgment; it accelerates the iteration cycle and surfaces options we might otherwise miss.

This project was as much about building a thinking tool as a composition tool. The "ego in me wants there to be a way where people can tap into my way of thinking about music and use it to their benefit—even long after I die" (from project check-in notes). By open-sourcing the code and documenting the design philosophy, the system becomes a teaching artifact—a way to share not just music, but a method for making music.





References

[1]	Music and emotion — Wikipedia. Overview of theories including BRECVEM, neuroscience, and structural features. https://en.wikipedia.org/wiki/Music_and_emotion

[2]	Algorithmic composition — Wikipedia. Survey of models and methods including translational systems and hybrid approaches. https://en.wikipedia.org/wiki/Algorithmic_composition

[3]	Music (Expressive qualities) — Encyclopaedia Britannica. Historical and cultural context on music as expressive art. https://www.britannica.com/art/music/Expressive-qualities

[4]	Music Emotion Recognition: A State of the Art Review — ISMIR 2010 (conference paper PDF) [open access]. https://archives.ismir.net/ismir2010/paper/000045.pdf

[5]	Music induces universal emotion-related psychophysiological responses — Egermann et al., Frontiers (open access). https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4286616

[6]	Emotional Responses to Music: The Essential Inclusion of Emotion Adaptability and Situational Context — Susino et al., Empirical Studies of the Arts (2024). https://journals.sagepub.com/doi/10.1177/02762374241237683

[7]	Musical emotions in the absence of music: A cross-cultural investigation — Susino et al., PLOS ONE (open access). https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7673536

[8]	AI Methods in Algorithmic Composition: A Comprehensive Survey — Fernandez & Vico (arXiv) [open access]. https://arxiv.org/abs/1402.0585

[9]	Juslin, P. N.; Västfjäll, D. (2008). "Emotional responses to music: The need to consider underlying mechanisms" — Behavioral and Brain Sciences. DOI: https://doi.org/10.1017/S0140525X08005293



[10]	Barry Harris masterclass — Video demonstrating using picked floor numbers as musical seeds (YouTube). https://www.youtube.com/watch?v=0-IRJsAi0ek

[11]	Kircher, Athanasius. Musurgia Universalis (1650). https://www.arca1650.info





Appendix: Technical Documentation

Code entry point:



Core engines:



(scale library, 60+ scales with metadata)

(scoring algorithm with BRECVEM emotion mapping) (lexical/phonetic analysis)

(syllable stress, vowel quality)



Default weight configuration (Balanced preset):



 	Emotional: 40%

 	Semantic: 30%

 	Intervallic: 20%

 	Contextual: 10%



Scale approximations: All non-12-TET scales flagged in	object



MIDI implementation: FastAPI server + loopMIDI virtual cable routing





Acknowledgements

Thanks to Professor John Paul Merz for feedback emphasizing the importance of shifting from tool-building to music-making, and for encouraging live demonstrations over purely written documentation. Thanks to AU music librarian for guidance on ethnomusicological sourcing. Thanks to classmates who served as first-time users and provided UI feedback. Special thanks to Barry Harris (posthumously) for teaching me to hear harmony as color rather than function.

